{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incredible-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import copy\n",
    "import torch\n",
    "import importlib\n",
    "\n",
    "import dataloader\n",
    "from dataloader.action_genome import AG, cuda_collate_fn\n",
    "from dataloader.movie_graph import MG\n",
    "\n",
    "from lib.config import Config\n",
    "from lib.evaluation_recall import BasicSceneGraphEvaluator\n",
    "from lib.evaluation_recall_mg import MGSceneGraphEvaluator\n",
    "from lib.object_detector import detector\n",
    "from lib.sttran import STTran"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-crown",
   "metadata": {},
   "source": [
    "### Initiate Dataloader for the MovieClips as well as the STTran network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "studied-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = Config()\n",
    "# print(conf)\n",
    "# for i in conf.args:\n",
    "#     print(i,':', conf.args[i])\n",
    "datasize = 'large'\n",
    "ag_data_path = \"../ActionGenome/dataset/ag/\"\n",
    "mg_data_path = \"../TER_MovieGraph/scene_library/\"\n",
    "mode = 'test'\n",
    "\n",
    "\n",
    "MG_dataset = MG(mode =mode, datasize = datasize, data_path = mg_data_path, filter_nonperson_box_frame=False, filter_small_box=False if mode == 'predcls' else True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "social-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "detector(\n",
       "  (fasterRCNN): resnet(\n",
       "    (RCNN_rpn): _RPN(\n",
       "      (RPN_Conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (RPN_cls_score): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (RPN_bbox_pred): Conv2d(512, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (RPN_proposal): _ProposalLayer()\n",
       "      (RPN_anchor_target): _AnchorTargetLayer()\n",
       "    )\n",
       "    (RCNN_proposal_target): _ProposalTargetLayer()\n",
       "    (RCNN_roi_pool): ROIPool(output_size=(7, 7), spatial_scale=0.0625)\n",
       "    (RCNN_roi_align): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0)\n",
       "    (RCNN_base): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (RCNN_top): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (RCNN_cls_score): Linear(in_features=2048, out_features=37, bias=True)\n",
       "    (RCNN_bbox_pred): Linear(in_features=2048, out_features=148, bias=True)\n",
       "  )\n",
       "  (ROI_Align): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg_dataloader = torch.utils.data.DataLoader(MG_dataset, shuffle=False, num_workers=0, collate_fn=cuda_collate_fn)\n",
    "\n",
    "\n",
    "gpu_device = torch.device('cuda:0')\n",
    "mode = 'sgdet'\n",
    "object_detector = detector(train=False, object_classes=MG_dataset.object_classes, use_SUPPLY=True, mode=mode).to(device=gpu_device)\n",
    "object_detector.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enabling-selling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word vector location: data data\n",
      "loading word vectors from data/data/glove.6B.200d.pt\n",
      "word vector location: /home/cong/Dokumente/neural-motifs-master/data /hom\n",
      "loading word vectors from data//home/cong/Dokumente/neural-motifs-master/data/glove.6B.200d.pt\n",
      "__background__ -> __background__ \n",
      "fail on __background__\n",
      "**************************************************\n",
      "CKPT pretrained_models/sgdet.tar is loaded\n"
     ]
    }
   ],
   "source": [
    "enc_layer = 1\n",
    "dec_layer = 3\n",
    "model_path = \"pretrained_models/sgdet.tar\"\n",
    "\n",
    "model = STTran(mode=mode,\n",
    "               attention_class_num=len(MG_dataset.attention_relationships),\n",
    "               spatial_class_num=len(MG_dataset.spatial_relationships),\n",
    "               contact_class_num=len(MG_dataset.contacting_relationships),\n",
    "               obj_classes=MG_dataset.object_classes,\n",
    "               enc_layer_num=enc_layer,\n",
    "               dec_layer_num=dec_layer).to(device=gpu_device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "ckpt = torch.load(model_path, map_location=gpu_device)\n",
    "model.load_state_dict(ckpt['state_dict'], strict=False)\n",
    "print('*'*50)\n",
    "print('CKPT {} is loaded'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "designing-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSTTranPrediction(model, data):\n",
    "    im_data = copy.deepcopy(data[0].cuda(0))\n",
    "    im_info = copy.deepcopy(data[1].cuda(0))\n",
    "    gt_boxes = copy.deepcopy(data[2].cuda(0))\n",
    "    num_boxes = copy.deepcopy(data[3].cuda(0))\n",
    "    index = data[4]\n",
    "    scene_id = data[5]\n",
    "    print(f\"Prediction and Scene ID: {scene_id}\")\n",
    "    print(im_data.shape, im_info.shape, gt_boxes.shape, num_boxes.shape)\n",
    "    gt_annotation = torch.zeros([im_data.shape[0], 1, 5])\n",
    "    \n",
    "    entry = object_detector(im_data, im_info, gt_boxes, num_boxes, gt_annotation, im_all=None)\n",
    "    pred = model(entry)\n",
    "    return entry, pred, scene_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-soundtrack",
   "metadata": {},
   "source": [
    "### Run some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sonic-calgary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction and Scene ID: 18\n",
      "torch.Size([12, 3, 600, 1064]) torch.Size([12, 3]) torch.Size([12, 1, 5]) torch.Size([12])\n",
      "Prediction and Scene ID: 14\n",
      "torch.Size([23, 3, 600, 1064]) torch.Size([23, 3]) torch.Size([23, 1, 5]) torch.Size([23])\n",
      "Prediction and Scene ID: 216\n",
      "torch.Size([18, 3, 600, 1064]) torch.Size([18, 3]) torch.Size([18, 1, 5]) torch.Size([18])\n",
      "Prediction and Scene ID: 163\n",
      "torch.Size([12, 3, 600, 1064]) torch.Size([12, 3]) torch.Size([12, 1, 5]) torch.Size([12])\n",
      "Prediction and Scene ID: 217\n",
      "torch.Size([6, 3, 600, 1064]) torch.Size([6, 3]) torch.Size([6, 1, 5]) torch.Size([6])\n",
      "Prediction and Scene ID: 213\n",
      "torch.Size([6, 3, 600, 1064]) torch.Size([6, 3]) torch.Size([6, 1, 5]) torch.Size([6])\n",
      "Prediction and Scene ID: 160\n",
      "torch.Size([26, 3, 600, 1064]) torch.Size([26, 3]) torch.Size([26, 1, 5]) torch.Size([26])\n",
      "Prediction and Scene ID: 11\n",
      "torch.Size([42, 3, 600, 1064]) torch.Size([42, 3]) torch.Size([42, 1, 5]) torch.Size([42])\n",
      "Prediction and Scene ID: 165\n",
      "torch.Size([22, 3, 600, 1064]) torch.Size([22, 3]) torch.Size([22, 1, 5]) torch.Size([22])\n",
      "Prediction and Scene ID: 103\n",
      "torch.Size([25, 3, 600, 1064]) torch.Size([25, 3]) torch.Size([25, 1, 5]) torch.Size([25])\n",
      "Prediction and Scene ID: 68\n",
      "torch.Size([73, 3, 600, 1064]) torch.Size([73, 3]) torch.Size([73, 1, 5]) torch.Size([73])\n",
      "Prediction and Scene ID: 221\n",
      "torch.Size([45, 3, 600, 1064]) torch.Size([45, 3]) torch.Size([45, 1, 5]) torch.Size([45])\n",
      "Prediction and Scene ID: 154\n",
      "torch.Size([21, 3, 600, 1064]) torch.Size([21, 3]) torch.Size([21, 1, 5]) torch.Size([21])\n",
      "Prediction and Scene ID: 209\n",
      "torch.Size([21, 3, 600, 1064]) torch.Size([21, 3]) torch.Size([21, 1, 5]) torch.Size([21])\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "obj_entries = {}\n",
    "with torch.no_grad():\n",
    "    for b, data in enumerate(mg_dataloader):\n",
    "        if b < 14: #if you let this loop try and make predictions for all scenes, there will be an error for certain scenes\n",
    "            obj_entry, pred, scene_id = makeSTTranPrediction(model, data)\n",
    "            predictions[scene_id] = pred\n",
    "            obj_entries[scene_id] = obj_entry\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "satisfied-diabetes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['boxes', 'scores', 'distribution', 'pred_labels', 'features', 'fmaps', 'im_info', 'pred_scores', 'pair_idx', 'im_idx', 'human_idx', 'union_feat', 'union_box', 'spatial_masks', 'attention_distribution', 'spatial_distribution', 'contacting_distribution'])\n"
     ]
    }
   ],
   "source": [
    "scene_id = 14\n",
    "# scene_id = 18\n",
    "pred = predictions[scene_id]\n",
    "obj = obj_entries[scene_id]\n",
    "print(pred.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interested-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxes                     torch.Size([178, 5])\n",
      "scores                    torch.Size([185])\n",
      "distribution              torch.Size([178, 36])\n",
      "pred_labels               torch.Size([178])\n",
      "features                  torch.Size([178, 2048])\n",
      "fmaps                     torch.Size([23, 1024, 38, 67])\n",
      "im_info                   torch.Size([])\n",
      "pred_scores               torch.Size([178])\n",
      "pair_idx                  torch.Size([155, 2])\n",
      "im_idx                    torch.Size([155])\n",
      "human_idx                 torch.Size([23, 1])\n",
      "union_feat                torch.Size([155, 1024, 7, 7])\n",
      "union_box                 torch.Size([155, 5])\n",
      "spatial_masks             torch.Size([155, 2, 27, 27])\n",
      "attention_distribution    torch.Size([155, 3])\n",
      "spatial_distribution      torch.Size([155, 6])\n",
      "contacting_distribution   torch.Size([155, 17])\n"
     ]
    }
   ],
   "source": [
    "#explore the different elements returned with a prediction\n",
    "for k in pred.keys():\n",
    "    print(k.ljust(25), pred[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-habitat",
   "metadata": {},
   "source": [
    "## Convert Tensor Predictions to Readable Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "constitutional-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MGSceneGraphEvaluator(\n",
    "    mode=mode,\n",
    "    AG_object_classes=MG_dataset.object_classes,\n",
    "    AG_all_predicates=MG_dataset.relationship_classes,\n",
    "    AG_attention_predicates=MG_dataset.attention_relationships,\n",
    "    AG_spatial_predicates=MG_dataset.spatial_relationships,\n",
    "    AG_contacting_predicates=MG_dataset.contacting_relationships,\n",
    "    iou_threshold=0.5,\n",
    "    constraint='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adopted-genetics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['looking_at', 'not_looking_at', 'unsure', 'above', 'beneath', 'in_front_of', 'behind', 'on_the_side_of', 'in', 'carrying', 'covered_by', 'drinking_from', 'eating', 'have_it_on_the_back', 'holding', 'leaning_on', 'lying_on', 'not_contacting', 'other_relationship', 'sitting_on', 'standing_on', 'touching', 'twisting', 'wearing', 'wiping', 'writing_on']\n"
     ]
    }
   ],
   "source": [
    "print(MG_dataset.relationship_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "canadian-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tripletsToWords(triplets, object_classes, relationship_classes):\n",
    "    triplet_words = []\n",
    "    for sub1, rel, sub2 in triplets:\n",
    "        triplet_words.append([object_classes[sub1], relationship_classes[rel],object_classes[sub2]])\n",
    "    return triplet_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "processed-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_by_frame = evaluator.evaluate_scene_graph(pred)\n",
    "# for i,t in enumerate(triplets_in_word):\n",
    "#     print(triplet_boxes[i][0], t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "artistic-registrar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0:\n",
      "['doorknob', 'on_the_side_of', 'person']\n",
      "['person', 'holding', 'doorknob']\n",
      "['person', 'not_looking_at', 'doorknob']\n",
      "['person', 'touching', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['doorknob', 'on_the_side_of', 'person']\n",
      "['person', 'holding', 'doorknob']\n",
      "['person', 'not_looking_at', 'doorknob']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['doorknob', 'on_the_side_of', 'person']\n",
      "['person', 'holding', 'doorknob']\n",
      "['person', 'not_looking_at', 'doorknob']\n",
      "['doorknob', 'on_the_side_of', 'person']\n",
      "['person', 'holding', 'doorknob']\n",
      "['person', 'not_looking_at', 'doorknob']\n",
      "['doorway', 'behind', 'person']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['door', 'behind', 'person']\n",
      "['person', 'not_contacting', 'door']\n",
      "['person', 'not_looking_at', 'door']\n",
      "['person', 'not_contacting', 'door']\n",
      "['door', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'door']\n",
      "\n",
      "Frame 1:\n",
      "['person', 'not_contacting', 'table']\n",
      "['table', 'in_front_of', 'person']\n",
      "['shelf', 'on_the_side_of', 'person']\n",
      "['person', 'not_contacting', 'shelf']\n",
      "['person', 'not_looking_at', 'table']\n",
      "['person', 'not_looking_at', 'shelf']\n",
      "['person', 'not_contacting', 'cup/glass/bottle']\n",
      "['cup/glass/bottle', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'cup/glass/bottle']\n",
      "['person', 'holding', 'cup/glass/bottle']\n",
      "['cup/glass/bottle', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'cup/glass/bottle']\n",
      "['person', 'holding', 'paper/notebook']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['person', 'holding', 'paper/notebook']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['person', 'holding', 'book']\n",
      "['book', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'paper/notebook']\n",
      "['person', 'not_looking_at', 'book']\n",
      "['person', 'not_looking_at', 'paper/notebook']\n",
      "['person', 'holding', 'book']\n",
      "['book', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'picture']\n",
      "['picture', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'picture']\n",
      "['person', 'not_looking_at', 'book']\n",
      "['person', 'holding', 'paper/notebook']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['person', 'not_looking_at', 'paper/notebook']\n",
      "['sofa/couch', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'sofa/couch']\n",
      "['person', 'not_looking_at', 'sofa/couch']\n",
      "['person', 'holding', 'paper/notebook']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'paper/notebook']\n",
      "['person', 'holding', 'paper/notebook']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'paper/notebook']\n",
      "\n",
      "Frame 2:\n",
      "['person', 'not_contacting', 'table']\n",
      "['table', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'table']\n",
      "['person', 'holding', 'cup/glass/bottle']\n",
      "['cup/glass/bottle', 'in_front_of', 'person']\n",
      "['cup/glass/bottle', 'in_front_of', 'person']\n",
      "['person', 'holding', 'cup/glass/bottle']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['food', 'in_front_of', 'person']\n",
      "['person', 'touching', 'food']\n",
      "['person', 'not_looking_at', 'cup/glass/bottle']\n",
      "['person', 'looking_at', 'food']\n",
      "['person', 'not_looking_at', 'cup/glass/bottle']\n",
      "['person', 'touching', 'book']\n",
      "['book', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'book']\n",
      "['person', 'touching', 'box']\n",
      "['box', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'box']\n",
      "['person', 'sitting_on', 'sofa/couch']\n",
      "['sofa/couch', 'beneath', 'person']\n",
      "['person', 'not_looking_at', 'sofa/couch']\n",
      "\n",
      "Frame 3:\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'wearing', 'clothes']\n",
      "['person', 'not_contacting', 'picture']\n",
      "['picture', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['doorway', 'in', 'person']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['doorway', 'in', 'person']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'touching', 'clothes']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'unsure', 'picture']\n",
      "['person', 'holding', 'bag']\n",
      "['bag', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'mirror']\n",
      "['person', 'looking_at', 'bag']\n",
      "['mirror', 'in', 'person']\n",
      "['person', 'not_looking_at', 'mirror']\n",
      "\n",
      "Frame 4:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'holding', 'book']\n",
      "['book', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'book']\n",
      "['person', 'touching', 'book']\n",
      "['book', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'book']\n",
      "['person', 'holding', 'bag']\n",
      "['bag', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'bag']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'holding', 'paper/notebook']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'paper/notebook']\n",
      "['person', 'touching', 'table']\n",
      "['table', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'table']\n",
      "\n",
      "Frame 5:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "\n",
      "Frame 6:\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['table', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'table']\n",
      "['person', 'not_looking_at', 'table']\n",
      "['person', 'holding', 'book']\n",
      "['book', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'book']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['person', 'not_contacting', 'mirror']\n",
      "['mirror', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'mirror']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['person', 'holding', 'paper/notebook']\n",
      "['person', 'looking_at', 'paper/notebook']\n",
      "['person', 'sitting_on', 'sofa/couch']\n",
      "['sofa/couch', 'beneath', 'person']\n",
      "['person', 'not_looking_at', 'sofa/couch']\n",
      "['person', 'sitting_on', 'sofa/couch']\n",
      "['sofa/couch', 'beneath', 'person']\n",
      "['person', 'not_looking_at', 'sofa/couch']\n",
      "\n",
      "Frame 7:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['doorway', 'in', 'person']\n",
      "['clothes', 'in_front_of', 'person']\n",
      "['person', 'holding', 'clothes']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'looking_at', 'clothes']\n",
      "['door', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'door']\n",
      "['doorway', 'on_the_side_of', 'person']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'wearing', 'doorway']\n",
      "['person', 'looking_at', 'door']\n",
      "['clothes', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'clothes']\n",
      "['person', 'looking_at', 'clothes']\n",
      "\n",
      "Frame 8:\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'wearing', 'clothes']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'wearing', 'clothes']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['doorway', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'door']\n",
      "['door', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'not_looking_at', 'door']\n",
      "['broom', 'on_the_side_of', 'person']\n",
      "['person', 'holding', 'broom']\n",
      "['person', 'not_looking_at', 'broom']\n",
      "\n",
      "Frame 9:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'closet/cabinet']\n",
      "['closet/cabinet', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'closet/cabinet']\n",
      "['shelf', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'shelf']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'looking_at', 'shelf']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['doorway', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'window']\n",
      "['window', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'window']\n",
      "['mirror', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'mirror']\n",
      "['person', 'looking_at', 'doorway']\n",
      "['person', 'looking_at', 'mirror']\n",
      "\n",
      "Frame 10:\n",
      "['person', 'not_contacting', 'table']\n",
      "['table', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'shelf']\n",
      "['shelf', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'table']\n",
      "['food', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'food']\n",
      "['book', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'book']\n",
      "['person', 'not_contacting', 'picture']\n",
      "['picture', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'picture']\n",
      "['food', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'food']\n",
      "['person', 'looking_at', 'food']\n",
      "['person', 'looking_at', 'shelf']\n",
      "['person', 'looking_at', 'book']\n",
      "['sandwich', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'sandwich']\n",
      "['food', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'food']\n",
      "['cup/glass/bottle', 'in_front_of', 'person']\n",
      "['person', 'holding', 'cup/glass/bottle']\n",
      "['person', 'not_looking_at', 'food']\n",
      "['person', 'not_looking_at', 'cup/glass/bottle']\n",
      "['person', 'not_looking_at', 'food']\n",
      "['person', 'not_looking_at', 'sandwich']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'paper/notebook']\n",
      "['person', 'looking_at', 'paper/notebook']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'paper/notebook']\n",
      "['person', 'looking_at', 'paper/notebook']\n",
      "\n",
      "Frame 11:\n",
      "['person', 'not_contacting', 'shelf']\n",
      "['shelf', 'on_the_side_of', 'person']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'shelf']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'mirror']\n",
      "['mirror', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'mirror']\n",
      "['door', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'door']\n",
      "['person', 'looking_at', 'door']\n",
      "['person', 'not_contacting', 'mirror']\n",
      "['mirror', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'mirror']\n",
      "['mirror', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'mirror']\n",
      "['person', 'looking_at', 'mirror']\n",
      "\n",
      "Frame 12:\n",
      "['person', 'not_contacting', 'table']\n",
      "['table', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'shelf']\n",
      "['shelf', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'table']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['person', 'not_looking_at', 'shelf']\n",
      "['bed', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'bed']\n",
      "['person', 'not_looking_at', 'bed']\n",
      "['sofa/couch', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'sofa/couch']\n",
      "['person', 'not_looking_at', 'sofa/couch']\n",
      "\n",
      "Frame 13:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'on_the_side_of', 'person']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'wearing', 'clothes']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['door', 'on_the_side_of', 'person']\n",
      "['person', 'not_contacting', 'door']\n",
      "['doorway', 'in', 'person']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'not_contacting', 'door']\n",
      "['door', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'door']\n",
      "['person', 'not_looking_at', 'door']\n",
      "\n",
      "Frame 14:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['doorway', 'in', 'person']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['doorway', 'on_the_side_of', 'person']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'not_contacting', 'door']\n",
      "['door', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'door']\n",
      "\n",
      "Frame 15:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['door', 'on_the_side_of', 'person']\n",
      "['person', 'not_contacting', 'door']\n",
      "['person', 'not_looking_at', 'door']\n",
      "\n",
      "Frame 16:\n",
      "['person', 'not_contacting', 'table']\n",
      "['table', 'in_front_of', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['person', 'not_looking_at', 'table']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['person', 'not_contacting', 'cup/glass/bottle']\n",
      "['cup/glass/bottle', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'cup/glass/bottle']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['person', 'touching', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'dish']\n",
      "['dish', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'dish']\n",
      "['mirror', 'behind', 'person']\n",
      "['person', 'not_looking_at', 'mirror']\n",
      "['person', 'touching', 'mirror']\n",
      "\n",
      "Frame 17:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['floor', 'beneath', 'person']\n",
      "['person', 'standing_on', 'floor']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_contacting', 'closet/cabinet']\n",
      "['closet/cabinet', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'closet/cabinet']\n",
      "['person', 'not_contacting', 'mirror']\n",
      "['mirror', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'mirror']\n",
      "['person', 'unsure', 'floor']\n",
      "['person', 'not_contacting', 'window']\n",
      "['window', 'in_front_of', 'person']\n",
      "['person', 'not_contacting', 'shelf']\n",
      "['shelf', 'in_front_of', 'person']\n",
      "['person', 'unsure', 'clothes']\n",
      "['person', 'looking_at', 'window']\n",
      "['person', 'looking_at', 'shelf']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['doorway', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'doorway']\n",
      "\n",
      "Frame 18:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['doorway', 'in', 'person']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['doorway', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'not_contacting', 'door']\n",
      "['door', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'door']\n",
      "\n",
      "Frame 19:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'door']\n",
      "['door', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'door']\n",
      "['door', 'on_the_side_of', 'person']\n",
      "['person', 'not_contacting', 'door']\n",
      "['person', 'not_looking_at', 'door']\n",
      "\n",
      "Frame 20:\n",
      "['person', 'wearing', 'clothes']\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'holding', 'clothes']\n",
      "['clothes', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['doorway', 'behind', 'person']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'touching', 'chair']\n",
      "['doorway', 'on_the_side_of', 'person']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['chair', 'in_front_of', 'person']\n",
      "['person', 'holding', 'towel']\n",
      "['towel', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'looking_at', 'chair']\n",
      "['person', 'looking_at', 'towel']\n",
      "\n",
      "Frame 21:\n",
      "['person', 'not_contacting', 'table']\n",
      "['table', 'in_front_of', 'person']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['person', 'not_looking_at', 'table']\n",
      "['person', 'sitting_on', 'chair']\n",
      "['chair', 'beneath', 'person']\n",
      "['person', 'not_looking_at', 'chair']\n",
      "['person', 'not_contacting', 'mirror']\n",
      "['mirror', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'mirror']\n",
      "['person', 'holding', 'book']\n",
      "['book', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'book']\n",
      "['person', 'holding', 'dish']\n",
      "['dish', 'in_front_of', 'person']\n",
      "['person', 'looking_at', 'dish']\n",
      "['sofa/couch', 'beneath', 'person']\n",
      "['person', 'sitting_on', 'sofa/couch']\n",
      "['person', 'not_looking_at', 'sofa/couch']\n",
      "['person', 'sitting_on', 'sofa/couch']\n",
      "['sofa/couch', 'beneath', 'person']\n",
      "['person', 'not_looking_at', 'sofa/couch']\n",
      "\n",
      "Frame 22:\n",
      "['clothes', 'in', 'person']\n",
      "['person', 'wearing', 'clothes']\n",
      "['person', 'not_looking_at', 'clothes']\n",
      "['person', 'holding', 'book']\n",
      "['book', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'book']\n",
      "['doorway', 'in', 'person']\n",
      "['person', 'not_contacting', 'doorway']\n",
      "['person', 'not_looking_at', 'doorway']\n",
      "['person', 'not_contacting', 'closet/cabinet']\n",
      "['closet/cabinet', 'on_the_side_of', 'person']\n",
      "['person', 'not_looking_at', 'closet/cabinet']\n",
      "['person', 'holding', 'paper/notebook']\n",
      "['paper/notebook', 'in_front_of', 'person']\n",
      "['person', 'not_looking_at', 'paper/notebook']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, frame in enumerate(triplets_by_frame):\n",
    "    triplets = frame[0]\n",
    "    boxes = frame[0]\n",
    "    print(f\"Frame {i}:\")\n",
    "    trips = tripletsToWords(triplets, MG_dataset.object_classes, MG_dataset.relationship_classes)\n",
    "    for trip in trips:\n",
    "        print(trip)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
